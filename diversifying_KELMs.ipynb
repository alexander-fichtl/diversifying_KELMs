{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexander-fichtl/diversifying_KELMs/blob/main/diversifying_KELMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca3YJyN14DQ0"
      },
      "outputs": [],
      "source": [
        "# mount your drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LRgjbukJi0M"
      },
      "outputs": [],
      "source": [
        "# check gpu availability\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlxsSwOb4SOf",
        "outputId": "8bf3daf2-0c07-4286-e8ef-e7577c1dc4f5"
      },
      "source": [
        "# clone MoP code base\n",
        "\n",
        "!git clone https://github.com/cambridgeltl/mop.git\n",
        "\n",
        "# move to directory\n",
        "%cd drive/MyDrive/your_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_TybGjQ4mM5"
      },
      "outputs": [],
      "source": [
        "# install python3.8 to make MoP code base compatible\n",
        "\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.8 python3.8-dev python3.8-distutils libpython3.8-dev\n",
        "\n",
        "# change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
        "\n",
        "# install pip\n",
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!python3 get-pip.py --force-reinstall\n",
        "\n",
        "# install dependencies\n",
        "!python3 -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor\n",
        "\n",
        "# link to google package\n",
        "!ln -s /usr/local/lib/python3.8/dist-packages/google # \\ /usr/local/lib/python3.7/dist-packages/google\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uaTqdxk4ogM"
      },
      "outputs": [],
      "source": [
        "#install and import torch first to avoid problems with metis\n",
        "!pip3 install torch==1.7.0 # torchvision torchaudio torchtext\n",
        "\n",
        "import torch\n",
        "!ls\n",
        "!pip3 install pandas\n",
        "!pip3 install scipy\n",
        "!pip3 install tabulate\n",
        "!pip3 install protobuf==3.20.*\n",
        "!pip3 install wandb\n",
        "!pip3 install cmake\n",
        "!pip3 install scikit-learn\n",
        "!pip3 install nltk\n",
        "\n",
        "# Change working directory\n",
        "\n",
        "%cd src/metis-5.1.0\n",
        "\n",
        "!make config shared=1 prefix=~/.local/\n",
        "!make install\n",
        "!cp ~/.local/lib/libmetis.so /usr/lib/libmetis.so\n",
        "!export METIS_DLL=/usr/lib/libmetis.so\n",
        "!pip3 install metis-python\n",
        "\n",
        "\n",
        "%cd ..\n",
        "\n",
        "!ls\n",
        "!pip3 install -e adapter-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w2HKYl4E43sh"
      },
      "outputs": [],
      "source": [
        "%cd knowledge_infusion/entity_prediction/\n",
        "\n",
        "MODEL=\"dmis-lab/biobert-v1.1\"\n",
        "TOKENIZER=\"dmis-lab/biobert-v1.1\"\n",
        "\n",
        "# MODEL=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
        "# TOKENIZER=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
        "# MODEL=\"michiyasunaga/BioLinkBERT-base\"\n",
        "# TOKENIZER=\"michiyasunaga/BioLinkBERT-base\"\n",
        "\n",
        "INPUT_DIR=\"../../../kg_dir/\"\n",
        "OUTPUT_DIR=\"model_dir\"\n",
        "KG_NAME=\"ontochem_full_rel_data_cropped\"\n",
        "ADAPTER_NAMES=\"entity_predict\"\n",
        "PARTITION=20\n",
        "\n",
        "!python3 run_pretrain.py \\\n",
        "--model $MODEL \\\n",
        "--tokenizer $TOKENIZER \\\n",
        "--input_dir $INPUT_DIR$KG_NAME \\\n",
        "--output_dir $OUTPUT_DIR \\\n",
        "--n_partition $PARTITION \\\n",
        "--use_adapter \\\n",
        "--non_sequential \\\n",
        "--adapter_names  $ADAPTER_NAMES \\\n",
        "--amp \\\n",
        "--cuda \\\n",
        "--num_workers 32 \\\n",
        "--max_seq_length 64 \\\n",
        "--batch_size 256 \\\n",
        "--lr 1e-04 \\\n",
        "--epochs 1 \\\n",
        "--save_step 2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN6aGBSQ45q3"
      },
      "outputs": [],
      "source": [
        "%cd evaluate_tasks/med_qa/pubmedqa\n",
        "Dataset=\"PubMedQA\"\n",
        "MODEL_DIR=\"../../../../model_dir/\"\n",
        "DATA_DIR=\"../../../../data/BLURB/data/pubmedqa_new\"\n",
        "\n",
        "BASE_MODEL=\"dmis-lab/biobert-v1.1\"\n",
        "TOKENIZER=\"dmis-lab/biobert-v1.1\"\n",
        "# BASE_MODEL=\"michiyasunaga/BioLinkBERT-base\"\n",
        "# BASE_MODEL= \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
        "# MODEL=\"PubMedBERT-base_pure_S20Rel\"\n",
        "# BioLinkBERT-base_pubmedqa_S20Rel_new\n",
        "MODEL=\"onto3_BioBERT\"\n",
        "LR=0.5e-5 # 1e-5\n",
        "PRE_TRAIN_EPOCH=0\n",
        "T=1\n",
        "BATCH_SIZE=4 #4\n",
        "SEQ_LENGTH=512\n",
        "EPOCHS=30 # 25\n",
        "\n",
        "!python eval_pubmedqa.py \\\n",
        "    --data_dir $DATA_DIR   \\\n",
        "    --model_dir $MODEL_DIR \\\n",
        "    --tokenizer $BASE_MODEL   \\\n",
        "    --base_model $BASE_MODEL \\\n",
        "    --cuda \\\n",
        "    --temperature $T \\\n",
        "    --model $MODEL   \\\n",
        "    --pretrain_epoch $PRE_TRAIN_EPOCH \\\n",
        "    --max_seq_length $SEQ_LENGTH   \\\n",
        "    --batch_size $BATCH_SIZE \\\n",
        "    --lr $LR   \\\n",
        "    --epochs $EPOCHS \\\n",
        "    --repeat_runs 10 \\\n",
        "    --patience 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vefRI_ZFtzr_"
      },
      "outputs": [],
      "source": [
        "%cd evaluate_tasks/med_qa/bioasq7b\n",
        "\n",
        "DATASET=\"BioAsq\"\n",
        "MODEL_DIR=\"../../../../model_dir/\"\n",
        "DATA_DIR=\"../../../../data/BLURB/data/BioASQ/\"\n",
        "# BASE_MODEL= \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
        "# BASE_MODEL=\"dmis-lab/biobert-v1.1\"\n",
        "BASE_MODEL=\"michiyasunaga/BioLinkBERT-base\"\n",
        "MODEL=\"ontochem_15_full_rel_adapters\"\n",
        "T=1\n",
        "LR=0.5e-5\n",
        "TRAIN_MODE=\"fusion\"\n",
        "\n",
        "!python predict.py \\\n",
        "--train_mode $TRAIN_MODE \\\n",
        "--model_dir $MODEL_DIR \\\n",
        "--data_dir $DATA_DIR  \\\n",
        "--base_model $BASE_MODEL \\\n",
        "--tokenizer $BASE_MODEL  \\\n",
        "--model $MODEL  \\\n",
        "--max_seq_length 512   \\\n",
        "--batch_size 4 \\\n",
        "--lr $LR   \\\n",
        "--pretrain_epoch 0 \\\n",
        "--epochs 25 \\\n",
        "--temperature $T \\\n",
        "--cuda \\\n",
        "--repeat_runs 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFqPHd7FvdYB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNyNmENmr4M7"
      },
      "outputs": [],
      "source": [
        "%cd evaluate_tasks/med_qa/medqa\n",
        "\n",
        "DATASET=\"MEDQA\"\n",
        "MODEL_DIR=\"../../../../model_dir/\"\n",
        "DATA_DIR=\"../../../../data/BLURB/data/medqa/data_clean/questions/US/4_options/\"\n",
        "\n",
        "BASE_MODEL=\"michiyasunaga/BioLinkBERT-base\"\n",
        "MODEL=\"BioLinkBERT-base_pubmedqa_S20Rel_new\"\n",
        "T=1\n",
        "LR=1e-5\n",
        "BATCH_SIZE=4\n",
        "TRAIN_MODE=\"fusion\"\n",
        "\n",
        "!python run_medqa.py \\\n",
        "    --train_mode $TRAIN_MODE \\\n",
        "    --model_dir $MODEL_DIR \\\n",
        "    --data_dir $DATA_DIR  \\\n",
        "    --base_model $BASE_MODEL \\\n",
        "    --tokenizer $BASE_MODEL  \\\n",
        "    --model $MODEL  \\\n",
        "    --max_seq_length 512   \\\n",
        "    --batch_size $BATCH_SIZE \\\n",
        "    --lr $LR   \\\n",
        "    --repeat_runs 2 \\\n",
        "    --pretrain_epoch 0 \\\n",
        "    --epochs 25 \\\n",
        "    --temperature $T \\\n",
        "    --cuda \\\n",
        "    --repeat_runs 2 \\\n",
        "    --patience 3 \\\n",
        "    --gradient_accumulation_steps 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ymDj3TdPon-w"
      },
      "outputs": [],
      "source": [
        "%cd evaluate_tasks/med_doc_cls/hoc\n",
        "\n",
        "DATASET=\"Hoc\"\n",
        "MODEL_DIR=\"../../../../model_dir/\"\n",
        "DATA_DIR=\"../../../../data/BLURB/data/HoC/\"\n",
        "# BASE_MODEL=\"michiyasunaga/BioLinkBERT-base\"\n",
        "# BASE_MODEL= \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
        "BASE_MODEL=\"dmis-lab/biobert-v1.1\"\n",
        "MODEL=\"onto3_BioBERT\"\n",
        "\n",
        "T=1\n",
        "LR=1e-5\n",
        "BATCH_SIZE=16\n",
        "TRAIN_MODE=\"fusion\"\n",
        "\n",
        "!python eval_hoc.py \\\n",
        "--train_mode $TRAIN_MODE \\\n",
        "--model_dir $MODEL_DIR \\\n",
        "--data_dir $DATA_DIR  \\\n",
        "--base_model $BASE_MODEL \\\n",
        "--tokenizer $BASE_MODEL  \\\n",
        "--model $MODEL  \\\n",
        "--max_seq_length 128   \\\n",
        "--batch_size $BATCH_SIZE \\\n",
        "--lr $LR   \\\n",
        "--pretrain_epoch 0 \\\n",
        "--epochs 20 \\\n",
        "--repeat_runs 5 \\\n",
        "--temperature $T \\\n",
        "--cuda\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T87GrGNfv59t"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chXCfU_ngBqk"
      },
      "outputs": [],
      "source": [
        "%cd evaluate_tasks/med_nli\n",
        "\n",
        "DATASET=\"MEDNLI\"\n",
        "MODEL_DIR=\"../../../model_dir/\"\n",
        "DATA_DIR=\"../../../data/mednli/\"\n",
        "\n",
        "BASE_MODEL=\"michiyasunaga/BioLinkBERT-base\"\n",
        "\n",
        "# MODEL=\"BioLinkBERT-base_S20Rel_256bs_1e\"\n",
        "# BASE_MODEL= \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
        "# MODEL=\"PubMedBERT-base_pure_S20Rel\"\n",
        "# BASE_MODEL=\"michiyasunaga/BioLinkBERT-base\"\n",
        "\n",
        "MODEL=\"ontochem_15_full_rel_adapters\"\n",
        "\n",
        "\"\"\"\"\n",
        "LR=1e-5\n",
        "TRAIN_MODE=\"fusion\"\n",
        "python eval_nli.py \\\n",
        "--train_mode $TRAIN_MODE \\\n",
        "--model_dir $MODEL_DIR \\\n",
        "--data_dir $DATA_DIR  \\\n",
        "--base_model $BASE_MODEL \\\n",
        "--tokenizer $BASE_MODEL  \\\n",
        "--model $MODEL  \\\n",
        "--max_seq_length 256   \\\n",
        "--batch_size 16 \\\n",
        "--lr $LR   \\\n",
        "--repeat_runs 3 \\\n",
        "--pretrain_epoch 0 \\\n",
        "--epochs 25 \\\n",
        "--cuda\n",
        "\"\"\"\n",
        "LR=0.5e-5\n",
        "TRAIN_MODE=\"fusion\"\n",
        "!python eval_nli.py \\\n",
        "    --train_mode $TRAIN_MODE \\\n",
        "    --model_dir $MODEL_DIR \\\n",
        "    --data_dir $DATA_DIR  \\\n",
        "    --base_model $BASE_MODEL \\\n",
        "    --tokenizer $BASE_MODEL  \\\n",
        "    --model $MODEL  \\\n",
        "    --max_seq_length 256   \\\n",
        "    --batch_size 8 \\\n",
        "    --lr $LR   \\\n",
        "    --pretrain_epoch 0 \\\n",
        "    --epochs 25 \\\n",
        "    --cuda \\\n",
        "    --repeat_runs 3 \\\n",
        "    --patience 3 \\\n",
        "    # --gradient_accumulation_steps 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86dEI8lVah5F"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
